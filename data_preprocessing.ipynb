{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBIlvyl9V7Tz0L+No7iVKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kathdevx/emotionalAI/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhpZciivQLzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b25e14-9562-491d-f4f5-a26d43802a51"
      },
      "source": [
        "!pip install soundfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpIpw6vYxZVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8baa569d-e215-4fdb-e754-f8fdfd02d705"
      },
      "source": [
        "dir = '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/'\n",
        "partitions = '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/meta-info/Partitions.txt'\n",
        "\n",
        "import soundfile as sf\n",
        "import glob\n",
        "train = {'fname' : [], 'data': []}\n",
        "test = {'fname' : [], 'data': []}\n",
        "val = {'fname' : [], 'data': []}\n",
        "\n",
        "part_file = open('/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/meta-info/Partitions.txt')\n",
        "c = 20\n",
        "for line in part_file:\n",
        "    idx = line.find(';')\n",
        "    if line[:idx] == 'Train':\n",
        "        # train['fname'].append(line[:-1])\n",
        "        train['fname'].append(line[idx+2:-1])\n",
        "        c -= 1\n",
        "    if not c:\n",
        "        break\n",
        "\n",
        "c = 20\n",
        "for filename in glob.glob(dir+'*.wav'):\n",
        "    idx = filename.rfind('/')\n",
        "    fname = filename[idx+1:]\n",
        "    if fname in train['fname']:\n",
        "        f = sf.SoundFile(filename)\n",
        "        train['data'].append(filename)\n",
        "        c -= 1\n",
        "    if not c:\n",
        "        break\n",
        "\n",
        "print(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'fname': ['MSP-PODCAST_0023_0048.wav', 'MSP-PODCAST_0023_0205.wav', 'MSP-PODCAST_0023_0206.wav', 'MSP-PODCAST_0023_0229.wav', 'MSP-PODCAST_0023_0246.wav', 'MSP-PODCAST_0023_0247.wav', 'MSP-PODCAST_0023_0281.wav', 'MSP-PODCAST_0023_0406.wav', 'MSP-PODCAST_0023_0589.wav', 'MSP-PODCAST_0023_0018.wav', 'MSP-PODCAST_0023_0006.wav', 'MSP-PODCAST_0023_0044.wav', 'MSP-PODCAST_0023_0053.wav', 'MSP-PODCAST_0023_0078.wav', 'MSP-PODCAST_0023_0144.wav', 'MSP-PODCAST_0023_0217.wav', 'MSP-PODCAST_0023_0218.wav', 'MSP-PODCAST_0023_0248.wav', 'MSP-PODCAST_0023_0285.wav', 'MSP-PODCAST_0023_0327.wav'], 'data': ['/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0006.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0018.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0044.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0078.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0053.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0048.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0144.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0218.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0206.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0217.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0229.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0205.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0248.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0247.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0246.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0285.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0281.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0327.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0406.wav', '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0589.wav']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YbMAjuVDa1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0f2c77-147f-4e46-b196-00e6d4d34e84"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': ['/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0006.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0018.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0044.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0078.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0053.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0048.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0144.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0218.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0206.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0217.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0229.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0205.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0248.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0247.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0246.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0285.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0281.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0327.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0406.wav',\n",
              "  '/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/Audio Files/MSP-PODCAST_0023_0589.wav'],\n",
              " 'fname': ['MSP-PODCAST_0023_0048.wav',\n",
              "  'MSP-PODCAST_0023_0205.wav',\n",
              "  'MSP-PODCAST_0023_0206.wav',\n",
              "  'MSP-PODCAST_0023_0229.wav',\n",
              "  'MSP-PODCAST_0023_0246.wav',\n",
              "  'MSP-PODCAST_0023_0247.wav',\n",
              "  'MSP-PODCAST_0023_0281.wav',\n",
              "  'MSP-PODCAST_0023_0406.wav',\n",
              "  'MSP-PODCAST_0023_0589.wav',\n",
              "  'MSP-PODCAST_0023_0018.wav',\n",
              "  'MSP-PODCAST_0023_0006.wav',\n",
              "  'MSP-PODCAST_0023_0044.wav',\n",
              "  'MSP-PODCAST_0023_0053.wav',\n",
              "  'MSP-PODCAST_0023_0078.wav',\n",
              "  'MSP-PODCAST_0023_0144.wav',\n",
              "  'MSP-PODCAST_0023_0217.wav',\n",
              "  'MSP-PODCAST_0023_0218.wav',\n",
              "  'MSP-PODCAST_0023_0248.wav',\n",
              "  'MSP-PODCAST_0023_0285.wav',\n",
              "  'MSP-PODCAST_0023_0327.wav']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luXP3zbPAi6J"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRmXN7ZnDl0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab270e1a-243d-47d5-e16f-069b24bd6ee5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gGxyCnn3dis"
      },
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
        "import nltk\n",
        "\n",
        "def load_model():\n",
        "    tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "    model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "    return tokenizer, model\n",
        "\n",
        "def correct_sentence(input_text):\n",
        "    sentences = nltk.sent_tokenize(input_text)\n",
        "    return (' '.join([s.replace(s[0],s[0].capitalize(),1) for s in sentences]))\n",
        "\n",
        "def asr_transcript(input_file):\n",
        "\n",
        "    tokenizer, model = load_model()\n",
        "    \n",
        "    speech, fs = sf.read(input_file)\n",
        "\n",
        "    if len(speech.shape) > 1: \n",
        "        speech = speech[:,0] + speech[:,1]\n",
        "\n",
        "    if fs != 16000:\n",
        "        speech = librosa.resample(speech, fs, 16000)\n",
        "\n",
        "    input_values = tokenizer(speech, return_tensors=\"pt\").input_values\n",
        "    logits = model(input_values).logits\n",
        "    \n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    \n",
        "    transcription = tokenizer.decode(predicted_ids[0])\n",
        "\n",
        "    return correct_sentence(transcription.lower())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISutbJd_Cjva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6587f4e7-b16d-43e0-ff86-9258f2fd926a"
      },
      "source": [
        "f = open('/content/drive/Shareddrives/DNN -  audio files/Podcasts_Dataset/Data/sentences.txt', 'w')\n",
        "\n",
        "sentences = []\n",
        "\n",
        "for sample in train['data']:\n",
        "    idx = sample.rfind('/')\n",
        "    fname = sample[idx+1:] + ' '\n",
        "    f.write(fname)\n",
        "    f.write(asr_transcript(sample))\n",
        "    f.write('\\n')\n",
        "\n",
        "# asr_transcript(train['data'][3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:419: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  FutureWarning,\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dMce3VXIPHL"
      },
      "source": [
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}